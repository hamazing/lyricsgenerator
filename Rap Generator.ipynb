{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ready to be the next generation 6God ? \n",
    "\n",
    "It's generaly acknowledge that there is nothing better than learning by doing. I've been following a lot of tutorials \n",
    "latetly about AI & NLP (Natural Language Processing ). So as I've always been a rap music fan I thought it could be \n",
    "awsome to apply this to the technics I've been learning about machin learning and deep learning. \n",
    "**And here is how I found my self writing a Drake type Rap lyrics generator**\n",
    "\n",
    "What you'll see here next is the different steps I've chosen to take to build this little project.\n",
    "* Data gathering \n",
    "* Data preprocessing \n",
    "    * Tokenizing the data set\n",
    "    * Define the alphabet \n",
    "    * Create training sequences \n",
    "    * Label Encode training sequences &  One-Hot-Encode the dataset \n",
    "* The model \n",
    "    * Intro to the model used \n",
    "    * RNN and LSTM\n",
    "    * Building the model \n",
    "* Generating the lyrics\n",
    "    \n",
    "From now on I'll try to comment every cell of code so that you can get all what I'm doing during this or that specific cell. Feel free to reach out to me for any additionnal information ! \n",
    "\n",
    "Good reading ! \n",
    "\n",
    "\n",
    "Disclaimer : this document was built as a \"teaching material\" for the Christopher.ia a discovery volunteering group from Centrale Marseille. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our data getter "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have guessed already, in order to train our model to be the new rapper we need to teach him a bit of lyrics to make it rap like Drake (aka 6god ). To gather a data set I've simply scrapped a website like metrolyrics to get some songs from Drake's discography. \n",
    "\n",
    "If you want to get a good grasp on how to scrap a website I advice you to read this well documented tutorial : https://medium.freecodecamp.org/how-to-scrape-websites-with-python-and-beautifulsoup-5946935d93fe\n",
    "\n",
    "For the data set used here I've just created the drake-songs.csv using this technic. You can find the script for this in the same git repository you got this notebook from in the lyrics_getter.py \n",
    "\n",
    "As you'll see there on that script I've selected some 140 songs from Drake's discography that are stored in the data/drake-songs.csv file ! \n",
    "\n",
    "So as a frist step you'll need to run that script to gather data or just clone the git repository and you'll have it done. The next step is to process a bit our data to make it exploitable. The idea here is to change the lyrics into just raw text : no upper case letters, no ponctuation; just letters sequences and spaces. \n",
    "\n",
    "\n",
    "Let's import all the librarie we'll need for our work. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from __future__ import print_function\n",
    "from keras.callbacks import LambdaCallback\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.utils.data_utils import get_file\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import sys\n",
    "import io\n",
    "import re\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the songs from the csv\n",
    "songs = pd.read_csv('data/drake-songs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokeninzing the data into characters to feed to our model as it's a character based model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367372"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#gathering all the lyrics in one text check the lenght to see the result (normaly =367372 words)\n",
    "text = ''\n",
    "\n",
    "for index, row in songs['lyrics'].iteritems():\n",
    "    cleaned = str(row).lower().replace(' ', '\\n')\n",
    "    text = text + \" \".join(re.findall(r\"[a-z']+\", cleaned))\n",
    "    \n",
    "len(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now we have all the characters that might appear in our trainign data set from the previous tokenaziation step. In order to feed it to the model we need to check out all the unique characters. As our training data set is small we should stick to a small data set. So I've chosen to stay with the **english alphabet and some special characters** such as spaces.I've chosen to link every character to an index to make it easier to manipulate. Easy way out ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 28\n",
      "This is what our dict looks like:  {' ': 0, \"'\": 1, 'a': 2, 'b': 3, 'c': 4, 'd': 5, 'e': 6, 'f': 7, 'g': 8, 'h': 9, 'i': 10, 'j': 11, 'k': 12, 'l': 13, 'm': 14, 'n': 15, 'o': 16, 'p': 17, 'q': 18, 'r': 19, 's': 20, 't': 21, 'u': 22, 'v': 23, 'w': 24, 'x': 25, 'y': 26, 'z': 27}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokens = re.findall(r\"[a-z'\\s]\", text)\n",
    "# find all the unique chracters\n",
    "chars = sorted(list(set(tokens)))\n",
    "print('total chars:', len(chars))\n",
    "char_indexes = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print('This is what our dict looks like: ',char_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we know exactly what are the characters our model we'll be predicting, we can start **creating the training data set**. Actually the model we'll be predicting the next character based on the previous ones. A simple idea that can be represented by the model calculating the $max_{all-seeds} (P(next char \\mid seed ))$ where the next char is just the next character. So if we look at it closely, the model we'll learn that the most probable character after a \"Trying to make it\" is a \" \". Yeah, just a space. Next sequences would be : \"rying to make it \" and the prediction we'll be \"s\" as the song says : \"Trying to make it simple ...\" \n",
    "\n",
    "Got it ? \n",
    "So basically all we're doing is creating inputs of 40 characters lenght for one character output. As simple as that. The most famialiar with data sets from you would notice that we are increasing the data set seize significantly by predicting one character at a time.  \n",
    "\n",
    "Let's go for the creation of the data set ! \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb sequences: 367332\n"
     ]
    }
   ],
   "source": [
    "# cut the text in semi-redundant sequences of maxlen characters\n",
    "maxlen = 20\n",
    "step = 1 #the size at every iteration \n",
    "sentences = [] #List of sequences \n",
    "next_chars = [] #list of next characters that our model should predict\n",
    "\n",
    "for i in range(0, len(text) - maxlen, step):\n",
    "    sentences.append(text[i: i + maxlen])\n",
    "    next_chars.append(text[i + maxlen])\n",
    "    \n",
    "print('nb sequences:', len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorization...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print('Vectorization...')\n",
    "#Creat empty matrices for input and output sets\n",
    "x = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "#We iterate over the matrices and covert all character to number \n",
    "# This is what we call Label Encoding process and One hot Vectorization :\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        x[i, t, char_indexes[char]] = 1\n",
    "    y[i, char_indexes[next_chars[i]]] = 1\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually in order to predict the next charcater based on the previous characters, we are going to use Reccuring Neural Network. More specificaly, Long Short Term Memory Networks. If you're unfamiliar with thse models here are the best tutorials I've found on the net that can be very helpful. I strongly advise you to read these : \n",
    "\n",
    "* RNN : https://towardsdatascience.com/introduction-to-recurrent-neural-network-27202c3945f3 by Pranoy Radhakrishnan\n",
    "* LSTM : https://medium.com/@kangeugine/long-short-term-memory-lstm-concept-cb3283934359 by Eugine Kang\n",
    "\n",
    "To build the model, I'm not going to reinvent boiling water. If you look a bit at the documentation of Keras you'll find easily that LSTM is already implemented. Only need to give it the right inputs and form the right outputs. \n",
    "\n",
    "Nothing crazy done here only building the model ! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Build model...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "# build the model: a single LSTM\n",
    "print('Build model...')\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=RMSprop(lr=0.01))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               80384     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 28)                3612      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 28)                0         \n",
      "=================================================================\n",
      "Total params: 83,996\n",
      "Trainable params: 83,996\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_epoch_end(epoch, logs):\n",
    "    print('Generating text after Epoch: %d' % epoch)\n",
    "\n",
    "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
    "    for diversity in [0.2, 0.5]:\n",
    "        print('diversity:', diversity)\n",
    "\n",
    "        generated = ''\n",
    "        sentence = text[start_index: start_index + maxlen]\n",
    "        generated += sentence\n",
    "        print('Generating with seed: \"' + sentence + '\"')\n",
    "        sys.stdout.write(generated)\n",
    "\n",
    "        for i in range(400):\n",
    "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
    "            for t, char in enumerate(sentence):\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "            preds = model.predict(x_pred, verbose=0)[0]\n",
    "            next_index = sample(preds, diversity)\n",
    "            next_char = indices_char[next_index]\n",
    "\n",
    "            generated += next_char\n",
    "            sentence = sentence[1:] + next_char\n",
    "\n",
    "            sys.stdout.write(next_char)\n",
    "            sys.stdout.flush()\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "122444/122444 [==============================] - 90s 731us/step - loss: 1.9469\n",
      "----- Generating text after Epoch: 0\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ntial i'm here for you niggas i guess a \"\n",
      "ntial i'm here for you niggas i guess a from the the better the she the the with the the the still i con't the and i con't the the the still the and i see i could the the some to the to stort the starte i con a from the the the the some the show the some the the the the the some the the see the she you still the she the to better i con a prech the the still i got to the better the the some the some the shot i see i got the she the the s\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ntial i'm here for you niggas i guess a \"\n",
      "ntial i'm here for you niggas i guess a frim you could the to and me firdd i could i'm to thing i feel nigga in the broce i seen this you could thing i fuck to fick the money never the the plote the starting you seen i'm to cout the the troped i see it hot i don't the got the of the shone it i seent on you netta me the more the say and i'm and the try ain't from the bet i know it you're still you need it you to say you and i some my sin\n",
      "Epoch 2/10\n",
      "122444/122444 [==============================] - 99s 807us/step - loss: 1.5809\n",
      "----- Generating text after Epoch: 1\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" fuck i look like hoe i look like yes an\"\n",
      " fuck i look like hoe i look like yes and i got a carring and i say i have it i got a come i got a prace i don't can tell be cause i know you know you was and i start the could the cause you know you can carruck i got a but i got a pontind i don't we the bout the time i got it the same i cause i was and i got a carring i got a prother the when i say i'm the cause i got a come i got a coming i say i don't been the same i say i love it i \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" fuck i look like hoe i look like yes an\"\n",
      " fuck i look like hoe i look like yes and a popting on i got was rack with more to shit them so trought i got a comec and my plean i got a comploon and and i carruar about the copt and the but i'm started i a bertat on that that i know what the same a crearur like i know you we here hah you a pitch that work i wanna back a prabire a mive but i say i know they can now a warte i don't fave you whing you take to go really know they can't t\n",
      "Epoch 3/10\n",
      "122444/122444 [==============================] - 99s 808us/step - loss: 1.4832\n",
      "----- Generating text after Epoch: 2\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ind it must be hard to be that fine when\"\n",
      "ind it must be hard to be that fine when i got it i got it i was a don't do the come to the cause i got it to make the way that you the way it the way it i wanna some but i can tell the world to be the way it the cause i got it i wanna make the way it world to be the way the way it i was a lot the way they wanna but you the way it i can't be the cause i wanna show the trust the city i wanna be the come on the trust i wanna we got me i c\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ind it must be hard to be that fine when\"\n",
      "ind it must be hard to be that fine when i was you don't ever this got up the hand i could to from a that i'm tor a mover she cause the same but you the got it i do a cordo got a bame we don't be been i do to got patie with it i deal of the got the world and i move it like i been to back the are all that i got a same us and if cars at like that i with me that you got no no no the cause i'm on like and of the have i trust you work me i c\n",
      "Epoch 4/10\n",
      "122444/122444 [==============================] - 87s 714us/step - loss: 1.4254\n",
      "----- Generating text after Epoch: 3\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"g in this elevator zone alone i'm up so \"\n",
      "g in this elevator zone alone i'm up so some shit all the can be was i can see i get it i get it i'm some she don't wanna get it i get it i get it i get it i get it i get it i get it i get it "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:3: RuntimeWarning: divide by zero encountered in log\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i get it i'm so more i'm going the same i see they say i spend the move i see i get it i got a mocher i got a grown and i got a never got it all i should think i'm to me and i got a spack i get it i get it i get it i get it i get it i get it i get \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"g in this elevator zone alone i'm up so \"\n",
      "g in this elevator zone alone i'm up so from the crip to success i got to fun it man we wanna spange things with me on the for me they gon' i'm surriends all move and i'm going i get thet alone i hear here and from me i can't be to she can see i need to see somebody wanna plan hope bout on one me and is i can packed gettin' some go huse i don't know me i talk you don't know when you can i hope she dance and i'm going post on my rone in \n",
      "Epoch 5/10\n",
      "122444/122444 [==============================] - 79s 642us/step - loss: 1.3898\n",
      "----- Generating text after Epoch: 4\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"you looking good girl go go go get em gi\"\n",
      "you looking good girl go go go get em girl you gotta do the things i got the strent and the strented to get it the can be gon' to be the fuck and there i got the game and the sturt to me and i gotta hard to go hard to take me i got to me i love it to be gotta do it back to me i got to be in the strent in the team you and i got the fuck it i'm too good to get the strented to go hard to be the same to be like it i'm trying to the sturt it\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"you looking good girl go go go get em gi\"\n",
      "you looking good girl go go go get em girl i'm and a back in the istell your party to smoke i been looking it still i got the only back and with my my libe don't look a sitt in the clip we make my think i'm too look what it's okay it's okay it's okay you be here i said i'm on you hard you they gon' to be take to of the cance to but you don't hard to mind you getting that gon' looking to be like you contrace to be the flong i better in t\n",
      "Epoch 6/10\n",
      "122444/122444 [==============================] - 84s 690us/step - loss: 1.3622\n",
      "----- Generating text after Epoch: 5\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \" been plotting on the low scheming on th\"\n",
      " been plotting on the low scheming on the time that i'm trying to the same i'm belong the call me there's now it i'm the bout there i was and i'm the best i wanna be there's noter the chazy there it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay it's okay you know it i get it you know it i get it i \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \" been plotting on the low scheming on th\"\n",
      " been plotting on the low scheming on the brow still who we make the bitch somethin' i ain't from the new now her so comin' they fuckin' they say everythink shit and there in my brought there it before i belong there's people they know i'm the berice the same so i'm say yeah i'm the best i been the liffen i just be the fuck on the controlle but there's now i got the same fuckin' to dog where it i'm the stur but you say i love my bar i f\n",
      "Epoch 7/10\n",
      "122444/122444 [==============================] - 78s 637us/step - loss: 1.3421\n",
      "----- Generating text after Epoch: 6\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"an was pushin' a subaru hatchback man i'\"\n",
      "an was pushin' a subaru hatchback man i'm gone i wanna go hard the same that i wanna say it i wanna say the bar we got me do not start we got it i got the way i wanna say you wanna say it i'm on yeah i wanna say it i'm on yeah i wanna get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it i get it \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"an was pushin' a subaru hatchback man i'\"\n",
      "an was pushin' a subaru hatchback man i'm going i really have to get it sometime was go take the same when you had to be you could me everywhere i wanna do what you the just been go have no but it on the game a move the a weod you wanna pass the like the high and you got it shit the way on my they know that shit for the club the the at some say you know how to stay to probably hing i could see the fuck the sorr we go was a me the cense \n",
      "Epoch 8/10\n",
      "122444/122444 [==============================] - 85s 693us/step - loss: 1.3259\n",
      "----- Generating text after Epoch: 7\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"ive me loyalty and i don't gotta pay for\"\n",
      "ive me loyalty and i don't gotta pay for the cash the same i can't take the same that i can't say no time they could be the same i don't take the same to say no think i can't ever say no no no no no no no no no no no no no no no nei' go look a blubech and i say a granch i got it so the same to but i see it to take the controlla be the same they know they know they know they all the just to the same that you cause i can't be the same nig\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"ive me loyalty and i don't gotta pay for\"\n",
      "ive me loyalty and i don't gotta pay for no tor way no spend friends to be i got a but i seen on the back i got niggas i cause my love it the place down a nigga got my one they got a granpin' to coming a sport me and second to tell 'em to hase the one of my bigger i got a fell just a start i don't got me say i got your friends an my feel now i'm a suck when i'm a move and i'm a got some blet i'm the fuck to but i'm souno this shit i cou\n",
      "Epoch 9/10\n",
      "122444/122444 [==============================] - 83s 681us/step - loss: 1.3136\n",
      "----- Generating text after Epoch: 8\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"her cause money's under nothin my life i\"\n",
      "her cause money's under nothin my life i can't do the shit i got my shit i wanna do the shit i won't don't the plug on the stull my shit i got the club with the check i don't want to check with the she list not i don't want to do the same i got it i see i swear the came i got it the same i got a could nigga the plug and i said the start i got it the shit i got a nigga i can't trust the came i got it the cash and the way i don't get to t\n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"her cause money's under nothin my life i\"\n",
      "her cause money's under nothin my life i get it the why have nigga every time when i don't be eden i'm just got the city the wind up on the hat i'll slept up wheneres i got not i like is and i'm down you get the real we ain't not not a problem are i got a cloself and please i see how you're wave the way i'm gon' to do and i was just couldn't want to should and stay it we do i be for me up to do not a clus for but you don't you know wher\n",
      "Epoch 10/10\n",
      "122444/122444 [==============================] - 84s 685us/step - loss: 1.3044\n",
      "----- Generating text after Epoch: 9\n",
      "----- diversity: 0.2\n",
      "----- Generating with seed: \"enever i step outside the house i keep t\"\n",
      "enever i step outside the house i keep the same there i got the cause i never say you say you know that i got me the same there i don't wanna be some the same in the came i got to see me the same that i make me the same there i love the same i don't wanna be a couple the moraice the crected to can sound the came i don't workin' to the same there i say i don't wanna be some the things i wanna be in my family the same in the same and the \n",
      "----- diversity: 0.5\n",
      "----- Generating with seed: \"enever i step outside the house i keep t\"\n",
      "enever i step outside the house i keep the road i say you ain't skeer he deping to the temms i'm too siccest you that i don't do it with the cent to go the sure how i ain't ever you would be on the grave on a live used to the creb but you know that they know i bought me for me like the arrace to some cause you done done with the fuck in the grobart on my face i live a friends i start i know i got the giptin' to say it all the women i ma\n"
     ]
    }
   ],
   "source": [
    "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n",
    "\n",
    "history = model.fit(\n",
    "    x, \n",
    "    y,\n",
    "    batch_size=128,\n",
    "    epochs=10,\n",
    "    callbacks=[print_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x120e432e8>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The generator : \n",
    "\n",
    "Here is your generator. Feel free to send me any comments or feedback on this. Here are my contact info :\n",
    "* Email : laajajhamza@gmail.com\n",
    "* Github : https://github.com/hamazing \n",
    "\n",
    "Thanks for reading ! \n",
    "\n",
    "\n",
    "PS : run all the cells of the notebook one by one to get the input case here "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_output():\n",
    "    generated = ''\n",
    "    usr_input = input(\"Type in the seed and let the AI generate some Drake type lyrics for you :  \")\n",
    "\n",
    "    sentence = ('{0:0>' + str(Tx) + '}').format(usr_input).lower()\n",
    "    generated += usr_input \n",
    "\n",
    "    sys.stdout.write(\"\\n\\nHere is your poem: \\n\\n\") \n",
    "    sys.stdout.write(usr_input)\n",
    "    for i in range(400):\n",
    "\n",
    "        x_pred = np.zeros((1, Tx, len(chars)))\n",
    "\n",
    "        for t, char in enumerate(sentence):\n",
    "            if char != '0':\n",
    "                x_pred[0, t, char_indices[char]] = 1.\n",
    "\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = sample(preds, temperature = 0.2)\n",
    "        next_char = indices_char[next_index]\n",
    "\n",
    "        generated += next_char\n",
    "        sentence = sentence[1:] + next_char\n",
    "\n",
    "        sys.stdout.write(next_char)\n",
    "        sys.stdout.flush()\n",
    "\n",
    "        if next_char == '\\n':\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type in the seed and let the AI generat some Drake type lyrics :  too bad\n",
      "\n",
      "\n",
      "Here is your poem: \n",
      "\n",
      "too bad and the back and the same the same there i don't wanna be some the same there i all the same there i don't wanna be a time i wanna be some the bound to say i don't ever had the still the came i don't wanna be in the still with the bound the same there i don't know i don't want the creases there i don't wanna be some the club on my friends and i'm talkin' to the same there i don't wanna be a first"
     ]
    }
   ],
   "source": [
    "Tx = 40\n",
    "generate_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_model_weights(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
